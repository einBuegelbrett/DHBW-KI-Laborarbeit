{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Bayes-Netz zur Klassifikation von Wohnungsbewohnerkategorien (Datensatz \"wohnungen_1.csv\")\n",
    "Dieses Notebook stellt ein Modell auf Basis eines Bayes-Netzes vor, das verwendet wird, um die Bewohnerkategorie einer Wohnung basierend auf den Merkmalen der Wohnung zu klassifizieren.\n",
    "\n",
    "## Ziel\n",
    "Das Ziel dieses Projekts ist es, die Zusammenhänge zwischen den Eigenschaften einer Wohnung und den Bewohnerkategorien zu modellieren. Wir verwenden ein Bayes-Netz, um Wahrscheinlichkeiten vorherzusagen, auch wenn einige Informationen unvollständig sind.\n",
    "\n",
    "## Übersicht\n",
    "- **Datensatzbeschreibung**: Einführung in die Datenstruktur und Herausforderungen (z. B. unausgeglichene Klassen).\n",
    "- **Vorverarbeitung**: Bereinigung und Transformation der Daten.\n",
    "- **Modellaufbau**: Definition des Bayes-Netzes und Training.\n",
    "- **Evaluierung**: Beispiele und Ergebnisse.\n",
    "\n",
    "---\n",
    "\n",
    "## Vorbereitung\n",
    "Zuerst werden die benötigten Bibliotheken importiert."
   ],
   "id": "fde2aa547a810e3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:06:46.253399Z",
     "start_time": "2024-12-20T10:06:46.250029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from data_cleaning.text_to_numeric import get_zimmer, get_stockwerk, get_heizung, get_kindergarten, get_schule, get_bahn, get_miete, get_nebenkosten, get_alter, get_lage, get_kaution, get_kueche, get_bad, get_mobliert, get_quadratmeter"
   ],
   "id": "6f1ef128f362153a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Erläuterung:\n",
    "- **Bewohnerkategorie**: Der Datensatz enthält mehrere Spalten, mit verschiedenen Bewohnergruppen, wie DINK (Double Income No Kids) aber auch Alleinerziehend und Studierende, die die Zugehörigkeit zu einer Kategorie angeben. Diese werden in einer neuen Spalte `Bewohnerkategorie` zusammengefasst.\n",
    "- **Datenbereinigung**: Um den Datensatz korrekt nutzen zu können, müssen wir den Fließtext durch Zahlen ersetzen, damit die KI mit diesen Daten arbeiten kann. Dafür werden \"nein\" und \"ja\" in numerische Werte (0 und 1) umgewandelt. Werte wo es mehr als ein Wert gibt wie bei der Miete, wurde die Mitte der beiden Werte genommen. Dies Funktioniert über unser Python Skript \"data_cleaning.py\".\n"
   ],
   "id": "7965be172befa847"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:06:48.936469Z",
     "start_time": "2024-12-20T10:06:48.907737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = '../../data/Wohnungen_1.csv'  # Gegebenen Datensatz einlesen\n",
    "data = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Bewohnerkategorie bestimmen\n",
    "bewohnerkategorie = ['Studierende', 'Kleinfamilie', 'DINK', 'Alleinerziehende', 'Expatriate', 'Rentnerpaar']\n",
    "data['Bewohnerkategorie'] = data[bewohnerkategorie].apply(\n",
    "    lambda row: 'Keine' if all(row == 'nein') else ', '.join(row[row == 'ja'].index), axis=1)\n",
    "\n",
    "# Bereinigung der Daten\n",
    "data = data[data['Bewohnerkategorie'] != 'Keine']\n",
    "\n",
    "# Spalten, in denen \"nein\" durch 0 und \"ja\" durch 1 ersetzt werden sollen\n",
    "columns_to_replace = [\"Hausmeister\", \"Garage\", \"Aufzug\", \"Balkon\", \"Terrasse\", \"Kehrwoche\"]\n",
    "\n",
    "# Ersetze \"nein\" und \"ja\" in den angegebenen Spalten\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "data[columns_to_replace] = data[columns_to_replace].replace({'nein': 0, 'ja': 1})\n",
    "\n",
    "data['Zimmerzahl'] = data['Zimmerzahl'].apply(get_zimmer)\n",
    "data['Stockwerk'] = data['Stockwerk'].apply(get_stockwerk)\n",
    "data['Heizung'] = data['Heizung'].apply(get_heizung)\n",
    "data['Kindergarten'] = data['Kindergarten'].apply(get_kindergarten)\n",
    "data['Schule'] = data['Schule'].apply(get_schule)\n",
    "data['S-Bahn'] = data['S-Bahn'].apply(get_bahn)\n",
    "data['Miete'] = data['Miete'].apply(get_miete)\n",
    "data['Nebenkosten'] = data['Nebenkosten'].apply(get_nebenkosten)\n",
    "data['Alter'] = data['Alter'].apply(get_alter)\n",
    "data['Lage'] = data['Lage'].apply(get_lage)\n",
    "data['Kaution'] = data['Kaution'].apply(get_kaution)\n",
    "data['Kueche'] = data['Kueche'].apply(get_kueche)\n",
    "data['Bad'] = data['Bad'].apply(get_bad)\n",
    "data['Moebliert'] = data['Moebliert'].apply(get_mobliert)\n",
    "data['Quadratmeter'] = data['Quadratmeter'].apply(get_quadratmeter)\n",
    "\n",
    "#print(data.head())"
   ],
   "id": "2f42bf03eb73f939",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Modelle erstellen und trainieren\n",
    "Das Bayes-Netz wurde anhand der vorhandenen Daten trainiert, um die Beziehungen zwischen den Merkmalen und der Bewohnerkategorie zu modellieren. Aufgrund der hohen Anzahl von Merkmalen und Kategorien wurde bewusst ein einfacheres Bayes-Netz gewählt, da ein komplexeres Netzwerk rechnerisch aufwendiger und schwerer zu handhaben wäre.\n",
    "\n",
    "Für das Training des Modells kam der Maximum-Likelihood-Schätzer (ML-Schätzer) zum Einsatz. Dieser wurde gewählt, weil wir annehmen, dass die Daten unabhängig und identisch verteilt sind. Im Gegensatz dazu weist der Bayes-Schätzer eine Tendenz zugunsten der Klasse mit den meisten Beispielen auf. Da die Klassen in unserem Datensatz ungleichmäßig verteilt sind, war der Maximum-Likelihood-Schätzer die geeignetere Wahl."
   ],
   "id": "16a06fa427b2cf7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T10:08:15.121358Z",
     "start_time": "2024-12-20T10:08:14.346421Z"
    }
   },
   "source": [
    "# Modell 1\n",
    "model1 = BayesianNetwork([\n",
    "    ('Zimmerzahl', 'Bewohnerkategorie'),\n",
    "    ('Stockwerk', 'Bewohnerkategorie'),\n",
    "    ('Heizung', 'Bewohnerkategorie'),\n",
    "    ('S-Bahn', 'Bewohnerkategorie'),\n",
    "    ('Miete', 'Bewohnerkategorie'),\n",
    "    ('Alter', 'Bewohnerkategorie'),\n",
    "    ('Lage', 'Bewohnerkategorie')\n",
    "])\n",
    "# Modell fitten\n",
    "model1.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "# Inferenz durchführen\n",
    "inference = VariableElimination(model1)"
   ],
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.02 TiB for an array with shape (1117414932480,) and data type int8",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 27\u001B[0m\n\u001B[1;32m      2\u001B[0m model1 \u001B[38;5;241m=\u001B[39m BayesianNetwork([\n\u001B[1;32m      3\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mZimmerzahl\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBewohnerkategorie\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m      4\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStockwerk\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBewohnerkategorie\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKehrwoche\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBewohnerkategorie\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[1;32m     25\u001B[0m ])\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Modell fitten\u001B[39;00m\n\u001B[0;32m---> 27\u001B[0m \u001B[43mmodel1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMaximumLikelihoodEstimator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# Inferenz durchführen\u001B[39;00m\n\u001B[1;32m     29\u001B[0m inference \u001B[38;5;241m=\u001B[39m VariableElimination(model1)\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/pgmpy/models/BayesianNetwork.py:579\u001B[0m, in \u001B[0;36mBayesianNetwork.fit\u001B[0;34m(self, data, estimator, state_names, n_jobs, **kwargs)\u001B[0m\n\u001B[1;32m    572\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEstimator object should be a valid pgmpy estimator.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    574\u001B[0m _estimator \u001B[38;5;241m=\u001B[39m estimator(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    576\u001B[0m     data,\n\u001B[1;32m    577\u001B[0m     state_names\u001B[38;5;241m=\u001B[39mstate_names,\n\u001B[1;32m    578\u001B[0m )\n\u001B[0;32m--> 579\u001B[0m cpds_list \u001B[38;5;241m=\u001B[39m \u001B[43m_estimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_cpds(\u001B[38;5;241m*\u001B[39mcpds_list)\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/pgmpy/estimators/MLE.py:106\u001B[0m, in \u001B[0;36mMaximumLikelihoodEstimator.get_parameters\u001B[0;34m(self, n_jobs, weighted)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, JunctionTree):\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimate_potentials()\n\u001B[0;32m--> 106\u001B[0m parameters \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimate_cpd\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweighted\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;66;03m# TODO: A hacky solution to return correct value for the chosen backend. Ref #1675\u001B[39;00m\n\u001B[1;32m    110\u001B[0m parameters \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m parameters]\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/joblib/parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[1;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[0;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[1;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[1;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[1;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[1;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[1;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/joblib/parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/pgmpy/estimators/MLE.py:160\u001B[0m, in \u001B[0;36mMaximumLikelihoodEstimator.estimate_cpd\u001B[0;34m(self, node, weighted)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mestimate_cpd\u001B[39m(\u001B[38;5;28mself\u001B[39m, node, weighted\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    115\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;124;03m    Method to estimate the CPD for a given variable.\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;124;03m    ╘══════╧══════╧══════╧══════╧══════╛\u001B[39;00m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 160\u001B[0m     state_counts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate_counts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweighted\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweighted\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# if a column contains only `0`s (no states observed for some configuration\u001B[39;00m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# of parents' states) fill that column uniformly instead\u001B[39;00m\n\u001B[1;32m    164\u001B[0m     state_counts\u001B[38;5;241m.\u001B[39miloc[:, (state_counts\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mall(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/pgmpy/estimators/base.py:264\u001B[0m, in \u001B[0;36mParameterEstimator.state_counts\u001B[0;34m(self, variable, weighted, **kwargs)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;124;03mReturn counts how often each state of 'variable' occurred in the data.\u001B[39;00m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;124;03mIf the variable has parents, counting is done conditionally\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;124;03mc2  0   0   1   0\u001B[39;00m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    263\u001B[0m parents \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mget_parents(variable))\n\u001B[0;32m--> 264\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mParameterEstimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate_counts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvariable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweighted\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweighted\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/pgmpy/estimators/base.py:166\u001B[0m, in \u001B[0;36mBaseEstimator.state_counts\u001B[0;34m(self, variable, parents, weighted, reindex)\u001B[0m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reindex:\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;66;03m# reindex rows & columns to sort them and to add missing ones\u001B[39;00m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# missing row    = some state of 'variable' did not occur in data\u001B[39;00m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;66;03m# missing column = some state configuration of current 'variable's parents\u001B[39;00m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;66;03m#                  did not occur in data\u001B[39;00m\n\u001B[1;32m    165\u001B[0m     row_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_names[variable]\n\u001B[0;32m--> 166\u001B[0m     column_index \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMultiIndex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_product\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparents_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m     state_counts \u001B[38;5;241m=\u001B[39m state_count_data\u001B[38;5;241m.\u001B[39mreindex(\n\u001B[1;32m    168\u001B[0m         index\u001B[38;5;241m=\u001B[39mrow_index, columns\u001B[38;5;241m=\u001B[39mcolumn_index\n\u001B[1;32m    169\u001B[0m     )\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/pandas/core/indexes/multi.py:684\u001B[0m, in \u001B[0;36mMultiIndex.from_product\u001B[0;34m(cls, iterables, sortorder, names)\u001B[0m\n\u001B[1;32m    681\u001B[0m     names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mgetattr\u001B[39m(it, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m it \u001B[38;5;129;01min\u001B[39;00m iterables]\n\u001B[1;32m    683\u001B[0m \u001B[38;5;66;03m# codes are all ndarrays, so cartesian_product is lossless\u001B[39;00m\n\u001B[0;32m--> 684\u001B[0m codes \u001B[38;5;241m=\u001B[39m \u001B[43mcartesian_product\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(levels, codes, sortorder\u001B[38;5;241m=\u001B[39msortorder, names\u001B[38;5;241m=\u001B[39mnames)\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/pandas/core/reshape/util.py:65\u001B[0m, in \u001B[0;36mcartesian_product\u001B[0;34m(X)\u001B[0m\n\u001B[1;32m     59\u001B[0m     b \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros_like(cumprodX)\n\u001B[1;32m     61\u001B[0m \u001B[38;5;66;03m# error: Argument of type \"int_\" cannot be assigned to parameter \"num\" of\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;66;03m# type \"int\" in function \"tile_compat\"\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m     64\u001B[0m     tile_compat(\n\u001B[0;32m---> 65\u001B[0m         \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepeat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     66\u001B[0m         np\u001B[38;5;241m.\u001B[39mprod(a[i]),\n\u001B[1;32m     67\u001B[0m     )\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(X)\n\u001B[1;32m     69\u001B[0m ]\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:511\u001B[0m, in \u001B[0;36mrepeat\u001B[0;34m(a, repeats, axis)\u001B[0m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_repeat_dispatcher)\n\u001B[1;32m    468\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrepeat\u001B[39m(a, repeats, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    469\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;124;03m    Repeat each element of an array after themselves\u001B[39;00m\n\u001B[1;32m    471\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    509\u001B[0m \n\u001B[1;32m    510\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrepeat\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrepeats\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/DHBW-KI-Laborarbeit/.venv/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57\u001B[0m, in \u001B[0;36m_wrapfunc\u001B[0;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbound\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001B[39;00m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001B[39;00m\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;66;03m# exception has a traceback chain.\u001B[39;00m\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "\u001B[0;31mMemoryError\u001B[0m: Unable to allocate 1.02 TiB for an array with shape (1117414932480,) and data type int8"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Erstes Beispiel - Kleine Änderung\n",
    "Wir vergleichen die Ergebnisse des Modells anhand der Beispiele \"example_Zimmer_difference\" und \"example_Zimmer_difference2\". Dabei variiert nur die Anzahl der Zimmer, um zu sehen, wie sich die Bewohnerkategorie änderen kann."
   ],
   "id": "f864b7c7f34a8071"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T10:00:31.038760Z",
     "start_time": "2024-12-20T10:00:31.034141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_Zimmer_difference = {\n",
    "    \"Zimmerzahl\": 1,\n",
    "    \"Stockwerk\": 0,\n",
    "    \"Heizung\": 0,\n",
    "    \"S-Bahn\": 3,\n",
    "    \"Miete\": 276,\n",
    "    \"Alter\": 63,\n",
    "    \"Lage\": 4\n",
    "}\n",
    "\n",
    "# Wahrscheinlichkeiten für jede Zielklasse berechnen\n",
    "prediction = inference.query(variables=[\"Bewohnerkategorie\"], evidence=example_Zimmer_difference)\n",
    "\n",
    "# Wahrscheinlichkeiten in ein Dictionary umwandeln\n",
    "result = {str(state): float(prob) for state, prob in zip(prediction.state_names[\"Bewohnerkategorie\"], prediction.values)}\n",
    "\n",
    "# Ausgabe schön formatiert untereinander\n",
    "print(\"Wahrscheinlichkeiten für jede Bewohnerkategorie:\")\n",
    "for category, probability in result.items():\n",
    "    print(f\"{category}: {probability:%}\")"
   ],
   "id": "3b1b07f35d9991f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrscheinlichkeiten für jede Bewohnerkategorie:\n",
      "DINK: 16.666667%\n",
      "Expatriate: 16.666667%\n",
      "Kleinfamilie: 16.666667%\n",
      "Kleinfamilie, DINK: 16.666667%\n",
      "Studierende: 16.666667%\n",
      "Studierende, Alleinerziehende, Rentnerpaar: 16.666667%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T15:01:48.113152Z",
     "start_time": "2024-12-19T15:01:48.106060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "example_Zimmer_difference2 = {\n",
    "    \"Zimmerzahl\": 2,\n",
    "    \"Stockwerk\": 0,\n",
    "    \"Heizung\": 0,\n",
    "    \"S-Bahn\": 3,\n",
    "    \"Miete\": 276,\n",
    "    \"Alter\": 63,\n",
    "    \"Lage\": 4\n",
    "}\n",
    "\n",
    "# Wahrscheinlichkeiten für jede Zielklasse berechnen\n",
    "prediction = inference.query(variables=[\"Bewohnerkategorie\"], evidence=example_Zimmer_difference2)\n",
    "\n",
    "# Wahrscheinlichkeiten in ein Dictionary umwandeln\n",
    "result = {str(state): float(prob) for state, prob in zip(prediction.state_names[\"Bewohnerkategorie\"], prediction.values)}\n",
    "\n",
    "# Ausgabe schön formatiert untereinander\n",
    "print(\"Wahrscheinlichkeiten für jede Bewohnerkategorie:\")\n",
    "for category, probability in result.items():\n",
    "    print(f\"{category}: {probability:%}\")"
   ],
   "id": "8d7ff0330f8121cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrscheinlichkeiten für jede Bewohnerkategorie:\n",
      "DINK: 16.666667%\n",
      "Expatriate: 16.666667%\n",
      "Kleinfamilie: 16.666667%\n",
      "Kleinfamilie, DINK: 16.666667%\n",
      "Studierende: 16.666667%\n",
      "Studierende, Alleinerziehende, Rentnerpaar: 16.666667%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Auswertung der Ergebnisse\n",
    "Wie oben schon beschrieben, wurde nur die Anzahl der Zimmer variiert um zu sehen, wie sich die Bewohnerkategorie änderen kann. Hierbei wurde festgestellt, dass selbst eine kleine Änderung in einem Merkmal die Wahrscheinlichkeiten für die Bewohnerkategorien beeinflussen kann.\n",
    "\n",
    "### Potenzielle Erklärung\n",
    "Die Unterschiede in den Wahrscheinlichkeiten zwischen den beiden Beispielen können auf die Änderung der Zimmerzahl zurückgeführt werden. Eine höhere Zimmerzahl könnte bestimmte Bewohnerkategorien wie \"Kleinfamilien\" oder \"DINK\" bevorzugen, während eine niedrigere Zimmerzahl eher für \"Studierende\" oder \"Alleinerziehende\" geeignet sein könnte. Diese Ergebnisse zeigen, wie das Bayes-Netz die Beziehungen zwischen den Merkmalen der Wohnung und den Bewohnerkategorien modelliert und wie sich Änderungen in einem Merkmal auf die Wahrscheinlichkeiten der Kategorien auswirken können."
   ],
   "id": "97dfb2e147960e9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T02:44:23.239203Z",
     "start_time": "2024-12-20T02:44:22.963553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Modell 2\n",
    "model2 = BayesianNetwork([\n",
    "    ('Stockwerk', 'Bewohnerkategorie'),\n",
    "    ('Kindergarten', 'Bewohnerkategorie'),\n",
    "    ('Schule', 'Bewohnerkategorie'),\n",
    "    ('Miete', 'Bewohnerkategorie'),\n",
    "    ('Nebenkosten', 'Bewohnerkategorie'),\n",
    "    ('Kaution', 'Bewohnerkategorie'),\n",
    "    ('Kueche', 'Bewohnerkategorie'),\n",
    "])\n",
    "\n",
    "# Modell Fitten\n",
    "model2.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "# Inferenz durchführen\n",
    "inference = VariableElimination(model2)"
   ],
   "id": "df4a7b1d4ac18963",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Zweites Beispiel - Viel Änderung\n",
    "An diesem Modell vergleichen wir die Beispiele 'example_large_changes' und 'example_large_changes2', hierbei varriert sich, im Gegensatz zum Ersten Modell jede Kategorie mit drastischen Änderungen.\n"
   ],
   "id": "d5d34f882525bcd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T02:53:29.171156Z",
     "start_time": "2024-12-20T02:53:29.163298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_large_changes = {\n",
    "    \"Stockwerk\": get_stockwerk(\"2.Stock\"),\n",
    "    \"Schule\": get_schule(\"nah\"),\n",
    "    \"Miete\": get_miete(\"201-250\"),\n",
    "    \"Nebenkosten\": get_nebenkosten(\"unter 50\"),\n",
    "    \"Kaution\": get_kaution(\"ueber 3000\"),\n",
    "    \"Kueche\": get_kueche(\"Kueche (neu)\"),\n",
    "}\n",
    "\n",
    "# Wahrscheinlichkeiten für jede Zielklasse berechnen\n",
    "prediction = inference.query(variables=[\"Bewohnerkategorie\"], evidence=example_large_changes)\n",
    "\n",
    "# Wahrscheinlichkeiten in ein Dictionary umwandeln\n",
    "result = {str(state): float(prob) for state, prob in zip(prediction.state_names[\"Bewohnerkategorie\"], prediction.values)}\n",
    "\n",
    "# Ausgabe schön formatiert untereinander\n",
    "print(\"Wahrscheinlichkeiten für jede Bewohnerkategorie:\")\n",
    "for category, probability in result.items():\n",
    "    print(f\"{category}: {probability:.2%}\")"
   ],
   "id": "fae01df90fecb7ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrscheinlichkeiten für jede Bewohnerkategorie:\n",
      "DINK: 16.67%\n",
      "Expatriate: 16.67%\n",
      "Kleinfamilie: 16.67%\n",
      "Kleinfamilie, DINK: 16.67%\n",
      "Studierende: 16.67%\n",
      "Studierende, Alleinerziehende, Rentnerpaar: 16.67%\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T02:54:27.009729Z",
     "start_time": "2024-12-20T02:54:26.999180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_large_changes2 = {\n",
    "    \"Stockwerk\": get_stockwerk(\"7.Stock\"),\n",
    "    \"Schule\": get_schule(\"fern\"),\n",
    "    \"Miete\": get_miete(\"551-600\"),\n",
    "    \"Nebenkosten\": get_nebenkosten(\"151-200\"),\n",
    "    \"Kaution\": get_kaution(\"keine\"),\n",
    "    \"Kueche\": get_kueche(\"Kueche (alt)\"),\n",
    "}\n",
    "\n",
    "# Wahrscheinlichkeiten für jede Zielklasse berechnen\n",
    "prediction = inference.query(variables=[\"Bewohnerkategorie\"], evidence=example_large_changes2)\n",
    "\n",
    "# Wahrscheinlichkeiten in ein Dictionary umwandeln\n",
    "result = {str(state): float(prob) for state, prob in zip(prediction.state_names[\"Bewohnerkategorie\"], prediction.values)}\n",
    "\n",
    "# Ausgabe schön formatiert untereinander\n",
    "print(\"Wahrscheinlichkeiten für jede Bewohnerkategorie:\")\n",
    "for category, probability in result.items():\n",
    "    print(f\"{category}: {probability:.2%}\")"
   ],
   "id": "6f64590db7d20f33",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrscheinlichkeiten für jede Bewohnerkategorie:\n",
      "DINK: 16.67%\n",
      "Expatriate: 16.67%\n",
      "Kleinfamilie: 16.67%\n",
      "Kleinfamilie, DINK: 16.67%\n",
      "Studierende: 16.67%\n",
      "Studierende, Alleinerziehende, Rentnerpaar: 16.67%\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Auswertung der Ergebnisse\n",
    "Wie oben schon beschrieben, wurden alle im Modell angegeben Wohnungskategorien geändert. Hierbei wurde festgestellt, dass selbst bei größeren Änderungen, die Wahrscheinlichkeiten gleich bleiben kann.\n",
    "\n",
    "### Potenzielle Erklärung\n",
    "Eine mögliche Erklärung worauf das zu führen hat, kann sein das die Änderungen in den Merkmalen nicht ausreichen um die Wahrscheinlichkeiten zu beeinflussen. Welches zurückzuführen ist, dass die Merkmale nicht stark genug miteinander korrelieren, um die Bewohnerkategorien signifikant zu beeinflussen. Was davon kommen kann, dass die Beziehungen zwischen den Merkmalen und den Bewohnerkategorien im Modell möglicherweise nicht stark genug sind, um signifikante Änderungen in den Wahrscheinlichkeiten zu bewirken."
   ],
   "id": "4acd41bb8791b1fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# BEISPIELSUMGEBUNG FÜR DIE PERSON SVEN SENDKE MEIN TEAMPARTNER!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "test_model = BayesianNetwork([\n",
    "    # HIER DEINE MERKMALE EINFÜGEN\n",
    "    #SCHAU DIR DIE ANDEREN MERKMALE AN OBEN ODER MACH WIE HIER\n",
    "    #('Hausmeister', 'Bewohnerkategorie'),\n",
    "    #('Kindergarten', 'Bewohnerkategorie'),\n",
    "])\n",
    "inference_test = VariableElimination(test_model)"
   ],
   "id": "5b72910b426cc22f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "example_sven = {\n",
    "    # HIER DEINE WERTE EINFÜGEN\n",
    "    #SCHAU DIR DIE ANDEREN WERTE AN OBEN ODER MACH WIE HIER\n",
    "    # \"Hausmeister\": 0,  # Hausmeister vorhanden\n",
    "    # \"Kindergarten\": get_kindergarten(\"erreichbar\"),  # Keine Relevanz für Single High Income\n",
    "}\n",
    "\n",
    "# Wahrscheinlichkeiten für jede Zielklasse berechnen\n",
    "prediction = inference_test.query(variables=[\"Bewohnerkategorie\"], evidence=example_sven)\n",
    "\n",
    "# Wahrscheinlichkeiten in ein Dictionary umwandeln\n",
    "result = {str(state): float(prob) for state, prob in zip(prediction.state_names[\"Bewohnerkategorie\"], prediction.values)}\n",
    "\n",
    "# Ausgabe schön formatiert untereinander\n",
    "print(\"Wahrscheinlichkeiten für jede Bewohnerkategorie:\")\n",
    "for category, probability in result.items():\n",
    "    print(f\"{category}: {probability:.2%}\")"
   ],
   "id": "47f45fa5f298de63"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
